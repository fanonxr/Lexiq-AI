services:
  # PostgreSQL Database (for relational data)
  # Mimics Azure Database for PostgreSQL Flexible Server
  postgres:
    image: postgres:16
    container_name: lexiqai-db-local
    ports:
      - "5432:5432"
    environment:
      POSTGRES_USER: ${POSTGRES_USER:-admin}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-password}
      POSTGRES_DB: ${POSTGRES_DB:-lexiqai_local}
      TZ: UTC  # Set timezone explicitly
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./docker/postgres/init.sql:/docker-entrypoint-initdb.d/init.sql:ro
      - /etc/localtime:/etc/localtime:ro  # Sync with host time
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-admin} -d ${POSTGRES_DB:-lexiqai_local}"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - lexiqai-network

  # Redis Cache (for conversation state and caching)
  # Mimics Azure Cache for Redis
  redis:
    image: redis:7-alpine
    container_name: lexiqai-redis-local
    ports:
      - "6379:6379"
      - "6380:6380"  # SSL port (for compatibility)
    environment:
      TZ: UTC  # Set timezone explicitly
    command: >
      sh -c "
      if [ -n \"$$REDIS_PASSWORD\" ]; then
        redis-server --appendonly yes --requirepass \"$$REDIS_PASSWORD\"
      else
        redis-server --appendonly yes
      fi
      "
    volumes:
      - redis_data:/data
      - /etc/localtime:/etc/localtime:ro  # Sync with host time
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - lexiqai-network

  # Qdrant Vector Database (for RAG and vector storage)
  # Note: This is separate from PostgreSQL (which handles relational data only)
  qdrant:
    image: qdrant/qdrant:latest
    container_name: lexiqai-qdrant-local
    ports:
      - "6333:6333"  # REST API
      - "6334:6334"  # gRPC
    environment:
      QDRANT__SERVICE__GRPC_PORT: 6334
      TZ: UTC  # Set timezone explicitly
    volumes:
      - qdrant_data:/qdrant/storage
      - /etc/localtime:/etc/localtime:ro  # Sync with host time
    healthcheck:
      # Qdrant container is minimal and doesn't have common tools (wget, curl, ps, python)
      # Since we can verify it's working via HTTP from the host, we'll use a simple check
      # that always passes if the container is running (the service itself handles errors)
      # For production, consider using an external health check or sidecar
      test: ["CMD-SHELL", "exit 0"]  # Always pass - Qdrant will fail requests if unhealthy
      interval: 30s
      timeout: 5s
      retries: 1
      start_period: 5s
    networks:
      - lexiqai-network

  # API Core Service (Python FastAPI)
  # Authentication, user management, billing, and dashboard APIs
  api-core:
    build:
      context: .
      dockerfile: docker/api-core/Dockerfile
    container_name: lexiqai-api-core-local
    ports:
      - "8000:8000"
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      rabbitmq:
        condition: service_healthy
    volumes:
      - ./apps/api-core/src:/app/src:ro  # Read-only for production-like behavior
      - ./libs/py-common/src:/app/libs/py-common/src:ro  # Shared library
      - /etc/localtime:/etc/localtime:ro  # Sync with host time
    # Load environment variables from apps/api-core/.env
    # Each app in the monorepo has its own .env file
    environment:
      - TZ=UTC  # Set timezone explicitly
      - APP_NAME=api-core
      - APP_ENV=development
      - DEBUG=true
      - LOG_LEVEL=INFO
      # Internal service-to-service auth (disabled by default for local dev)
      - INTERNAL_API_KEY_ENABLED=${INTERNAL_API_KEY_ENABLED:-false}
      - INTERNAL_API_KEY=${INTERNAL_API_KEY:-}
      # Cognitive Orchestrator Configuration
      - COGNITIVE_ORCH_URL=http://cognitive-orch:8001
      - COGNITIVE_ORCH_API_KEY=${INTERNAL_API_KEY:-}
      - COGNITIVE_ORCH_TIMEOUT=30
      # RabbitMQ (publish ingestion jobs)
      - RABBITMQ_URL=amqp://${RABBITMQ_USER:-guest}:${RABBITMQ_PASSWORD:-guest}@rabbitmq:5672/
      - RABBITMQ_EXCHANGE_NAME=document-ingestion-exchange
      - RABBITMQ_ROUTING_KEY=document.ingestion
      # Azure Blob Storage (using actual Azure Storage Account)
      # Set these environment variables in your .env file or docker-compose.override.yml
      # Option 1: Use connection string (recommended for local dev)
      - STORAGE_ACCOUNT_NAME=${STORAGE_ACCOUNT_NAME:-}
      - STORAGE_CONNECTION_STRING=${STORAGE_CONNECTION_STRING:-}
      # Option 2: Use account key (alternative)
      - STORAGE_ACCOUNT_KEY=${STORAGE_ACCOUNT_KEY:-}
      # Option 3: Use Managed Identity (for Azure-hosted services)
      # NOTE: Set to false for local Docker development (Managed Identity doesn't work locally)
      - STORAGE_USE_MANAGED_IDENTITY=${STORAGE_USE_MANAGED_IDENTITY:-false}
      - DATABASE_URL=postgresql://${POSTGRES_USER:-admin}:${POSTGRES_PASSWORD:-password}@postgres:5432/${POSTGRES_DB:-lexiqai_local}
      - REDIS_URL=redis://redis:6379/0
      - CORS_ORIGINS=http://localhost:3000,http://localhost:3001
      # Azure AD B2C / Entra ID Configuration (required for token validation)
      # For Entra ID: Set TENANT_ID, CLIENT_ID, and INSTANCE (no policy needed)
      # For Azure AD B2C: Also set POLICY_SIGNUP_SIGNIN
      - AZURE_AD_B2C_TENANT_ID=${AZURE_AD_B2C_TENANT_ID:-}
      - AZURE_AD_B2C_CLIENT_ID=${AZURE_AD_B2C_CLIENT_ID:-}
      - AZURE_AD_B2C_CLIENT_SECRET=${AZURE_AD_B2C_CLIENT_SECRET:-}
      - AZURE_AD_B2C_INSTANCE=${AZURE_AD_B2C_INSTANCE:-https://login.microsoftonline.com}
      - AZURE_AD_B2C_USE_B2C=${AZURE_AD_B2C_USE_B2C:-false}
      - GOOGLE_CLIENT_ID=${GOOGLE_CLIENT_ID:-}
      - GOOGLE_CLIENT_SECRET=${GOOGLE_CLIENT_SECRET:-}
      # Twilio Configuration
      - TWILIO_ACCOUNT_SID=${TWILIO_ACCOUNT_SID:-}
      - TWILIO_AUTH_TOKEN=${TWILIO_AUTH_TOKEN:-}
      # API Base URL for webhooks (used when provisioning phone numbers)
      # - API_BASE_URL=${API_BASE_URL:-http://localhost:8000}
      - API_BASE_URL=${API_BASE_URL:-https://ungenerically-subcontiguous-vernetta.ngrok-free.dev}
      # Voice Gateway URL (used in TwiML responses)
      - VOICE_GATEWAY_URL=${VOICE_GATEWAY_URL:-wss://localhost:8080/streams/twilio}
      # Twilio Webhook Security
      - TWILIO_VALIDATE_SIGNATURES=${TWILIO_VALIDATE_SIGNATURES:-true}
      - PYTHONPATH=/app/src:/app/libs/py-common/src
      # Stripe Configuration
      - STRIPE_PUBLISHABLE_KEY=${STRIPE_PUBLISHABLE_KEY:-}
      - STRIPE_SECRET_KEY=${STRIPE_SECRET_KEY:-}
      - STRIPE_WEBHOOK_SECRET=${STRIPE_WEBHOOK_SECRET:-}
      - STRIPE_API_VERSION=${STRIPE_API_VERSION:-2024-11-20.acacia}
      - BILLING_BASE_URL=${BILLING_BASE_URL:-http://localhost:3000}
      - BILLING_CURRENCY=${BILLING_CURRENCY:-usd}
    command: uvicorn api_core.main:app --host 0.0.0.0 --port 8000 --reload
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      start_period: 40s
      retries: 3
    networks:
      - lexiqai-network

  # Cognitive Orchestrator Service (Python FastAPI)
  # LLM routing, RAG, conversation state management, and tool execution
  cognitive-orch:
    build:
      context: .
      dockerfile: docker/cognitive-orch/Dockerfile
    container_name: lexiqai-cognitive-orch-local
    ports:
      - "8001:8001"  # HTTP REST API
      - "50051:50051"  # gRPC (for Voice Gateway)
    depends_on:
      redis:
        condition: service_healthy
      qdrant:
        condition: service_started  # Use started instead of healthy since Qdrant health check is unreliable
    volumes:
      - ./apps/cognitive-orch/src:/app/src:ro  # Read-only for production-like behavior
      - ./libs/py-common/src:/app/libs/py-common/src:ro  # Shared library
      - /etc/localtime:/etc/localtime:ro  # Sync with host time
    environment:
      - TZ=UTC  # Set timezone explicitly
      - APP_NAME=cognitive-orch
      - ENVIRONMENT=development
      - DEBUG=true
      - LOG_LEVEL=INFO
      - HOST=0.0.0.0
      - PORT=8001
      - GRPC_PORT=50051
      # LLM Configuration (set these in .env.local or override)
      - DEFAULT_MODEL_NAME=${DEFAULT_MODEL_NAME:-azure/gpt-4o}
      - FALLBACK_MODEL_NAME=${FALLBACK_MODEL_NAME:-anthropic/claude-3-haiku}
      - ENABLE_FALLBACKS=${ENABLE_FALLBACKS:-true}
      - AZURE_API_KEY=${AZURE_API_KEY:-}
      - AZURE_API_BASE=${AZURE_API_BASE:-}
      - AZURE_API_VERSION=${AZURE_API_VERSION:-2024-02-15-preview}
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY:-}
      - GROQ_API_KEY=${GROQ_API_KEY:-}
      # Redis Configuration
      - REDIS_URL=redis://redis:6379/0
      - REDIS_PASSWORD=${REDIS_PASSWORD:-}
      - CONVERSATION_TTL=${CONVERSATION_TTL:-3600}
      # Qdrant Configuration
      - QDRANT_URL=http://qdrant:6333
      - QDRANT_API_KEY=${QDRANT_API_KEY:-}
      # Integration URLs
      - CORE_API_URL=http://api-core:8000
      - CORE_API_TIMEOUT=30
      # Internal API key for calling API Core internal endpoints
      - CORE_API_API_KEY=${INTERNAL_API_KEY:-}
      - INTEGRATION_WORKER_URL=http://integration-worker:8002
      - INTEGRATION_WORKER_TIMEOUT=30
      # Internal API Key Authentication (for protecting cognitive-orch endpoints)
      - INTERNAL_API_KEY_ENABLED=${INTERNAL_API_KEY_ENABLED:-false}
      - INTERNAL_API_KEY=${INTERNAL_API_KEY:-}
      # Context Window
      - MAX_CONTEXT_WINDOW=8000
      - MAX_HISTORY_MESSAGES=50
      # CORS
      - CORS_ORIGINS=http://localhost:3000,http://localhost:3001
      - PYTHONPATH=/app/src:/app/libs/py-common/src
    command: uvicorn cognitive_orch.main:app --host 0.0.0.0 --port 8001 --reload
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8001/health"]
      interval: 30s
      timeout: 10s
      start_period: 40s
      retries: 3
    networks:
      - lexiqai-network

  # RabbitMQ Message Queue (for document ingestion)
  rabbitmq:
    image: rabbitmq:3-management-alpine
    container_name: lexiqai-rabbitmq-local
    ports:
      - "5672:5672"  # AMQP port
      - "15672:15672"  # Management UI
    environment:
      RABBITMQ_DEFAULT_USER: ${RABBITMQ_USER:-guest}
      RABBITMQ_DEFAULT_PASS: ${RABBITMQ_PASSWORD:-guest}
      TZ: UTC  # Set timezone explicitly
    volumes:
      - rabbitmq_data:/var/lib/rabbitmq
      - /etc/localtime:/etc/localtime:ro  # Sync with host time
    healthcheck:
      test: ["CMD", "rabbitmq-diagnostics", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - lexiqai-network

  # Document Ingestion Service (Python FastAPI)
  # Processes knowledge base files for RAG: parsing, chunking, embedding, vector storage
  document-ingestion:
    build:
      context: .
      dockerfile: docker/document-ingestion/Dockerfile
    container_name: lexiqai-document-ingestion-local
    ports:
      - "8003:8003"
    depends_on:
      rabbitmq:
        condition: service_healthy
      qdrant:
        condition: service_started
      api-core:
        condition: service_started
    # Add restart policy to handle connection issues
    restart: unless-stopped
    volumes:
      - ./apps/document-ingestion/src:/app/src:ro
      - ./libs/py-common/src:/app/libs/py-common/src:ro  # Shared library
      # Mount .env so pydantic-settings can load it (compose env_file is stricter than python-dotenv)
      - ./apps/document-ingestion/.env:/app/.env:ro
      - /etc/localtime:/etc/localtime:ro  # Sync with host time
    environment:
      - TZ=UTC  # Set timezone explicitly
      - APP_NAME=document-ingestion
      - ENVIRONMENT=development
      - DEBUG=true
      - LOG_LEVEL=INFO
      - HOST=0.0.0.0
      - PORT=8003
      - RELOAD=true
      # RabbitMQ Configuration
      - RABBITMQ_URL=amqp://${RABBITMQ_USER:-guest}:${RABBITMQ_PASSWORD:-guest}@rabbitmq:5672/
      - RABBITMQ_QUEUE_NAME=document-ingestion
      - RABBITMQ_EXCHANGE_NAME=document-ingestion-exchange
      - RABBITMQ_DEAD_LETTER_QUEUE_NAME=document-ingestion-dlq
      - RABBITMQ_ROUTING_KEY=document.ingestion
      - RABBITMQ_PREFETCH_COUNT=10
      - RABBITMQ_QUEUE_DURABLE=true
      # Azure Blob Storage (using actual Azure Storage Account)
      # Set these environment variables in your .env file or docker-compose.override.yml
      # Option 1: Use connection string (recommended for local dev)
      - STORAGE_ACCOUNT_NAME=${STORAGE_ACCOUNT_NAME:-}
      - STORAGE_CONNECTION_STRING=${STORAGE_CONNECTION_STRING:-}
      # Option 2: Use account key (alternative)
      - STORAGE_ACCOUNT_KEY=${STORAGE_ACCOUNT_KEY:-}
      # Option 3: Use Managed Identity (for Azure-hosted services)
      # NOTE: Set to false for local Docker development (Managed Identity doesn't work locally)
      - STORAGE_USE_MANAGED_IDENTITY=${STORAGE_USE_MANAGED_IDENTITY:-false}
      # Embeddings config is loaded from ./apps/document-ingestion/.env via env_file
      # Qdrant Configuration
      - QDRANT_URL=http://qdrant:6333
      - QDRANT_API_KEY=${QDRANT_API_KEY:-}
      - QDRANT_COLLECTION_PREFIX=firm_
      - QDRANT_TIMEOUT=30
      # API Core Configuration
      - CORE_API_URL=http://api-core:8000
      - CORE_API_TIMEOUT=30
      # Internal API key for calling API Core internal endpoints
      - CORE_API_API_KEY=${INTERNAL_API_KEY:-}
      # Chunking Configuration
      - CHUNK_SIZE=1000
      - CHUNK_OVERLAP=200
      - CHUNKING_METHOD=sentence
      # Retry Configuration
      - MAX_RETRIES=3
      - RETRY_BACKOFF_FACTOR=2.0
      - RETRY_MAX_DELAY=300
      # Allowed File Types
      - ALLOWED_FILE_TYPES=pdf,docx,txt,md
      - PYTHONPATH=/app/src:/app/libs/py-common/src
    command: uvicorn document_ingestion.main:app --host 0.0.0.0 --port 8003 --reload
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8003/health"]
      interval: 30s
      timeout: 10s
      start_period: 40s
      retries: 3
    networks:
      - lexiqai-network

  # Voice Gateway Service (Go)
  # Handles Twilio WebSocket connections, STT, TTS, and Orchestrator integration
  voice-gateway:
    build:
      context: .
      dockerfile: docker/voice-gateway/Dockerfile
    container_name: lexiqai-voice-gateway-local
    ports:
      - "8080:8080"
    depends_on:
      cognitive-orch:
        condition: service_started
    restart: unless-stopped
    volumes:
      # Mount source for development (optional - comment out for production)
      - ./apps/voice-gateway:/app/src:ro
      - /etc/localtime:/etc/localtime:ro  # Sync with host time
    environment:
      - TZ=UTC  # Set timezone explicitly
      # Server Configuration
      - PORT=8080
      # Deepgram STT Configuration
      - DEEPGRAM_API_KEY=${DEEPGRAM_API_KEY:-}
      - DEEPGRAM_MODEL=${DEEPGRAM_MODEL:-nova-2}
      - DEEPGRAM_LANGUAGE=${DEEPGRAM_LANGUAGE:-en}
      # Cartesia TTS Configuration
      - CARTESIA_API_KEY=${CARTESIA_API_KEY:-}
      - CARTESIA_VOICE_ID=${CARTESIA_VOICE_ID:-sonic-english}
      - CARTESIA_MODEL_ID=${CARTESIA_MODEL_ID:-sonic}
      # Orchestrator gRPC Configuration
      - ORCHESTRATOR_URL=cognitive-orch:50051
      - ORCHESTRATOR_TLS_ENABLED=false
      - ORCHESTRATOR_TIMEOUT=30
      # Audio Processing Configuration
      - AUDIO_BUFFER_SIZE=${AUDIO_BUFFER_SIZE:-8192}
      - VAD_ENERGY_THRESHOLD=${VAD_ENERGY_THRESHOLD:-500.0}
      - VAD_SILENCE_FRAMES=${VAD_SILENCE_FRAMES:-10}
      # Resilience Configuration
      - CIRCUIT_BREAKER_MAX_FAILURES=${CIRCUIT_BREAKER_MAX_FAILURES:-5}
      - CIRCUIT_BREAKER_RESET_TIMEOUT=${CIRCUIT_BREAKER_RESET_TIMEOUT:-30}
      - RETRY_MAX_ATTEMPTS=${RETRY_MAX_ATTEMPTS:-3}
      - RETRY_INITIAL_BACKOFF=${RETRY_INITIAL_BACKOFF:-100}
      - RECONNECT_MAX_ATTEMPTS=${RECONNECT_MAX_ATTEMPTS:-5}
      - RECONNECT_BACKOFF=${RECONNECT_BACKOFF:-1000}
      # Observability Configuration
      - LOG_LEVEL=${LOG_LEVEL:-info}
      - LOG_PRETTY=${LOG_PRETTY:-false}
      - METRICS_ENABLED=${METRICS_ENABLED:-true}
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      start_period: 10s
      retries: 3
    networks:
      - lexiqai-network

  # Integration Worker (Celery worker for calendar sync and CRM integration)
  # Handles background job processing for calendar synchronization
  integration-worker:
    build:
      context: .
      dockerfile: docker/integration-worker/Dockerfile
    container_name: lexiqai-integration-worker-local
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      api-core:
        condition: service_started
    environment:
      # Service
      SERVICE_NAME: integration-worker
      ENVIRONMENT: development
      # Database (shared with api-core) - use postgresql:// format (will be converted to asyncpg internally)
      DATABASE_URL: postgresql://${POSTGRES_USER:-admin}:${POSTGRES_PASSWORD:-password}@postgres:5432/${POSTGRES_DB:-lexiqai_local}
      # Redis (Celery broker and result backend)
      REDIS_URL: redis://redis:6379/0
      # API Core service
      API_CORE_URL: http://localhost:8000
      # Internal API key for calling API Core internal endpoints
      CORE_API_API_KEY: ${INTERNAL_API_KEY:-}
      # Azure AD / Microsoft Graph (same as api-core)
      AZURE_AD_CLIENT_ID: ${AZURE_AD_B2C_CLIENT_ID:-}
      AZURE_AD_TENANT_ID: ${AZURE_AD_B2C_TENANT_ID:-}
      AZURE_AD_CLIENT_SECRET: ${AZURE_AD_B2C_CLIENT_SECRET:-}
      # Google Calendar API (Phase 5)
      GOOGLE_CLIENT_ID: ${GOOGLE_CLIENT_ID:-}
      GOOGLE_CLIENT_SECRET: ${GOOGLE_CLIENT_SECRET:-}
      # Webhook settings
      WEBHOOK_BASE_URL: ${WEBHOOK_BASE_URL:-http://localhost:8080}
      WEBHOOK_SECRET: ${WEBHOOK_SECRET:-change-me-in-production}
      # Sync settings
      SYNC_LOOKBACK_DAYS: ${SYNC_LOOKBACK_DAYS:-30}
      SYNC_LOOKAHEAD_DAYS: ${SYNC_LOOKAHEAD_DAYS:-90}
      SYNC_BATCH_SIZE: ${SYNC_BATCH_SIZE:-100}
      # Retry settings
      MAX_RETRIES: ${MAX_RETRIES:-3}
      RETRY_BACKOFF_SECONDS: ${RETRY_BACKOFF_SECONDS:-60}
      # Logging
      LOG_LEVEL: ${LOG_LEVEL:-INFO}
      PYTHONPATH: /app/src:/app/api-core/src:/app/libs/py-common/src
    command: celery -A integration_worker.celery_app worker --loglevel=info --concurrency=4
    healthcheck:
      test: ["CMD-SHELL", "celery -A integration_worker.celery_app inspect ping -d celery@$$HOSTNAME || exit 1"]
      interval: 30s
      timeout: 10s
      start_period: 40s
      retries: 3
    networks:
      - lexiqai-network
    restart: unless-stopped

  # Integration Worker Beat (Celery scheduler for periodic tasks)
  # Triggers scheduled tasks: calendar sync every 15 min, token refresh every hour
  integration-worker-beat:
    build:
      context: .
      dockerfile: docker/integration-worker/Dockerfile
    container_name: lexiqai-integration-worker-beat-local
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    environment:
      # Service
      SERVICE_NAME: integration-worker-beat
      ENVIRONMENT: development
      # Database (for querying integrations to sync) - use postgresql:// format (will be converted to asyncpg internally)
      DATABASE_URL: postgresql://${POSTGRES_USER:-admin}:${POSTGRES_PASSWORD:-password}@postgres:5432/${POSTGRES_DB:-lexiqai_local}
      # Redis (Celery broker)
      REDIS_URL: redis://redis:6379/0
      # API Core service
      API_CORE_URL: http://api-core:8000
      # Azure AD / Microsoft Graph
      AZURE_AD_CLIENT_ID: ${AZURE_AD_B2C_CLIENT_ID}
      AZURE_AD_TENANT_ID: ${AZURE_AD_B2C_TENANT_ID}
      AZURE_AD_CLIENT_SECRET: ${AZURE_AD_B2C_CLIENT_SECRET}
      # Logging
      LOG_LEVEL: ${LOG_LEVEL:-INFO}
      PYTHONPATH: /app/src:/app/api-core/src:/app/libs/py-common/src
    command: celery -A integration_worker.celery_app beat --loglevel=info
    healthcheck:
      test: ["CMD-SHELL", "pgrep -f 'celery.*beat' || exit 1"]
      interval: 30s
      timeout: 10s
      start_period: 40s
      retries: 3
    networks:
      - lexiqai-network
    restart: unless-stopped

  # Integration Worker Webhook Server (FastAPI for receiving webhooks)
  # Receives real-time notifications from Microsoft Graph, Google Calendar, etc.
  integration-worker-webhooks:
    build:
      context: .
      dockerfile: docker/integration-worker/Dockerfile
    container_name: lexiqai-integration-worker-webhooks-local
    ports:
      - "8002:8002"  # Webhook server port
    depends_on:
      redis:
        condition: service_healthy
    environment:
      # Service
      SERVICE_NAME: integration-worker-webhooks
      ENVIRONMENT: development
      # Database (for webhook processing)
      DATABASE_URL: postgresql://${POSTGRES_USER:-admin}:${POSTGRES_PASSWORD:-password}@postgres:5432/${POSTGRES_DB:-lexiqai_local}
      # Redis (Celery for queuing tasks)
      REDIS_URL: redis://redis:6379/0
      # API Core service
      API_CORE_URL: http://api-core:8000
      # Azure AD / Microsoft Graph
      AZURE_AD_CLIENT_ID: ${AZURE_AD_B2C_CLIENT_ID}
      AZURE_AD_TENANT_ID: ${AZURE_AD_B2C_TENANT_ID}
      AZURE_AD_CLIENT_SECRET: ${AZURE_AD_B2C_CLIENT_SECRET}
      # Webhook settings
      WEBHOOK_BASE_URL: ${WEBHOOK_BASE_URL:-http://localhost:8002}
      WEBHOOK_SECRET: ${WEBHOOK_SECRET:-change-me-in-production}
      # Logging
      LOG_LEVEL: ${LOG_LEVEL:-INFO}
      PYTHONPATH: /app/src:/app/api-core/src:/app/libs/py-common/src
    command: uvicorn integration_worker.main:app --host 0.0.0.0 --port 8002 --reload
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8002/health"]
      interval: 30s
      timeout: 10s
      start_period: 20s
      retries: 3
    networks:
      - lexiqai-network
    restart: unless-stopped

  # Web Frontend (Next.js 14)
  # The unified website + dashboard
#   web-frontend:
#     build:
#       context: ./apps/web-frontend
#       dockerfile: ../../docker/web-frontend/Dockerfile
#       args:
#         - NEXT_PUBLIC_API_URL=${NEXT_PUBLIC_API_URL:-http://localhost:8000}
#     container_name: lexiqai-web-frontend-local
#     ports:
#       - "3000:3000"
#     depends_on:
#       api-core:
#         condition: service_started
#     environment:
#       # Next.js
#       - NODE_ENV=development
#       - NEXT_PUBLIC_API_URL=${NEXT_PUBLIC_API_URL:-http://localhost:8000}
#       # Azure AD B2C (for authentication)
#       - NEXT_PUBLIC_AZURE_AD_CLIENT_ID=${AZURE_AD_B2C_CLIENT_ID}
#       - NEXT_PUBLIC_AZURE_AD_TENANT_ID=${AZURE_AD_B2C_TENANT_ID}
#       - NEXT_PUBLIC_AZURE_AD_AUTHORITY=${AZURE_AD_B2C_AUTHORITY:-https://login.microsoftonline.com/${AZURE_AD_B2C_TENANT_ID}}
#       # Feature flags
#       - NEXT_PUBLIC_ENABLE_SIGNUP=${ENABLE_SIGNUP:-true}
#     volumes:
#       - ./apps/web-frontend:/app:cached
#       - /app/node_modules
#       - /app/.next
#     command: npm run dev
#     networks:
#       - lexiqai-network

volumes:
  postgres_data:
    driver: local
  redis_data:
    driver: local
  qdrant_data:
    driver: local
  rabbitmq_data:
    driver: local

networks:
  lexiqai-network:
    driver: bridge
    name: lexiqai-network

