services:
  # PostgreSQL Database (for relational data)
  # Mimics Azure Database for PostgreSQL Flexible Server
  postgres:
    image: postgres:16
    container_name: lexiqai-db-local
    ports:
      - "5432:5432"
    environment:
      POSTGRES_USER: ${POSTGRES_USER:-admin}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-password}
      POSTGRES_DB: ${POSTGRES_DB:-lexiqai_local}
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./docker/postgres/init.sql:/docker-entrypoint-initdb.d/init.sql:ro
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-admin} -d ${POSTGRES_DB:-lexiqai_local}"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - lexiqai-network

  # Redis Cache (for conversation state and caching)
  # Mimics Azure Cache for Redis
  redis:
    image: redis:7-alpine
    container_name: lexiqai-redis-local
    ports:
      - "6379:6379"
      - "6380:6380"  # SSL port (for compatibility)
    command: >
      sh -c "
      if [ -n \"$$REDIS_PASSWORD\" ]; then
        redis-server --appendonly yes --requirepass \"$$REDIS_PASSWORD\"
      else
        redis-server --appendonly yes
      fi
      "
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - lexiqai-network

  # Qdrant Vector Database (for RAG and vector storage)
  # Note: This is separate from PostgreSQL (which handles relational data only)
  qdrant:
    image: qdrant/qdrant:latest
    container_name: lexiqai-qdrant-local
    ports:
      - "6333:6333"  # REST API
      - "6334:6334"  # gRPC
    volumes:
      - qdrant_data:/qdrant/storage
    environment:
      QDRANT__SERVICE__GRPC_PORT: 6334
    healthcheck:
      # Qdrant container is minimal and doesn't have common tools (wget, curl, ps, python)
      # Since we can verify it's working via HTTP from the host, we'll use a simple check
      # that always passes if the container is running (the service itself handles errors)
      # For production, consider using an external health check or sidecar
      test: ["CMD-SHELL", "exit 0"]  # Always pass - Qdrant will fail requests if unhealthy
      interval: 30s
      timeout: 5s
      retries: 1
      start_period: 5s
    networks:
      - lexiqai-network

  # Azurite (Azure Storage emulator) for local development
  # Used by api-core (uploads) and document-ingestion (downloads)
  azurite:
    image: mcr.microsoft.com/azure-storage/azurite:latest
    container_name: lexiqai-azurite-local
    ports:
      - "10000:10000"  # Blob service
    command: >
      azurite-blob --blobHost 0.0.0.0 --blobPort 10000 --location /data
    volumes:
      - azurite_data:/data
    networks:
      - lexiqai-network

  # API Core Service (Python FastAPI)
  # Authentication, user management, billing, and dashboard APIs
  api-core:
    build:
      context: .
      dockerfile: docker/api-core/Dockerfile
    container_name: lexiqai-api-core-local
    ports:
      - "8000:8000"
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      rabbitmq:
        condition: service_healthy
      azurite:
        condition: service_started
    volumes:
      - ./apps/api-core/src:/app/src:ro  # Read-only for production-like behavior
    # Load environment variables from apps/api-core/.env
    # Each app in the monorepo has its own .env file
    environment:
      - APP_NAME=api-core
      - APP_ENV=development
      - DEBUG=true
      - LOG_LEVEL=INFO
      # Internal service-to-service auth (disabled by default for local dev)
      - INTERNAL_API_KEY_ENABLED=${INTERNAL_API_KEY_ENABLED:-false}
      - INTERNAL_API_KEY=${INTERNAL_API_KEY:-}
      # RabbitMQ (publish ingestion jobs)
      - RABBITMQ_URL=amqp://${RABBITMQ_USER:-guest}:${RABBITMQ_PASSWORD:-guest}@rabbitmq:5672/
      - RABBITMQ_EXCHANGE_NAME=document-ingestion-exchange
      - RABBITMQ_ROUTING_KEY=document.ingestion
      # Azure Blob Storage (Azurite for local dev)
      - STORAGE_ACCOUNT_NAME=devstoreaccount1
      - STORAGE_ACCOUNT_KEY=Eby8vdM02xNOcqFlqUwJPLlmEtlCDXJ1OUzFT50uSRZ6IFsuFq2UVErCz4I6tq/K1SZFPTOtr/KBHBeksoGMGw==
      - STORAGE_USE_MANAGED_IDENTITY=false
      - STORAGE_CONNECTION_STRING=DefaultEndpointsProtocol=http;AccountName=devstoreaccount1;AccountKey=Eby8vdM02xNOcqFlqUwJPLlmEtlCDXJ1OUzFT50uSRZ6IFsuFq2UVErCz4I6tq/K1SZFPTOtr/KBHBeksoGMGw==;BlobEndpoint=http://azurite:10000/devstoreaccount1
      - DATABASE_URL=postgresql://${POSTGRES_USER:-admin}:${POSTGRES_PASSWORD:-password}@postgres:5432/${POSTGRES_DB:-lexiqai_local}
      - REDIS_URL=redis://redis:6379/0
      - CORS_ORIGINS=http://localhost:3000,http://localhost:3001
      # Azure AD B2C / Entra ID Configuration (required for token validation)
      # For Entra ID: Set TENANT_ID, CLIENT_ID, and INSTANCE (no policy needed)
      # For Azure AD B2C: Also set POLICY_SIGNUP_SIGNIN
      - AZURE_AD_B2C_TENANT_ID=${AZURE_AD_B2C_TENANT_ID:-}
      - AZURE_AD_B2C_CLIENT_ID=${AZURE_AD_B2C_CLIENT_ID:-}
      - AZURE_AD_B2C_CLIENT_SECRET=${AZURE_AD_B2C_CLIENT_SECRET:-}
      - AZURE_AD_B2C_INSTANCE=${AZURE_AD_B2C_INSTANCE:-https://login.microsoftonline.com}
      - AZURE_AD_B2C_USE_B2C=${AZURE_AD_B2C_USE_B2C:-false}
      # Twilio Configuration
      - TWILIO_ACCOUNT_SID=${TWILIO_ACCOUNT_SID:-}
      - TWILIO_AUTH_TOKEN=${TWILIO_AUTH_TOKEN:-}
      # API Base URL for webhooks (used when provisioning phone numbers)
      # - API_BASE_URL=${API_BASE_URL:-http://localhost:8000}
      - API_BASE_URL=${API_BASE_URL:-https://ungenerically-subcontiguous-vernetta.ngrok-free.dev}
      # Voice Gateway URL (used in TwiML responses)
      - VOICE_GATEWAY_URL=${VOICE_GATEWAY_URL:-wss://localhost:8080/streams/twilio}
      # Twilio Webhook Security
      - TWILIO_VALIDATE_SIGNATURES=${TWILIO_VALIDATE_SIGNATURES:-true}
      - PYTHONPATH=/app/src
    command: uvicorn api_core.main:app --host 0.0.0.0 --port 8000 --reload
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      start_period: 40s
      retries: 3
    networks:
      - lexiqai-network

  # Cognitive Orchestrator Service (Python FastAPI)
  # LLM routing, RAG, conversation state management, and tool execution
  cognitive-orch:
    build:
      context: .
      dockerfile: docker/cognitive-orch/Dockerfile
    container_name: lexiqai-cognitive-orch-local
    ports:
      - "8001:8001"  # HTTP REST API
      - "50051:50051"  # gRPC (for Voice Gateway)
    depends_on:
      redis:
        condition: service_healthy
      qdrant:
        condition: service_started  # Use started instead of healthy since Qdrant health check is unreliable
    volumes:
      - ./apps/cognitive-orch/src:/app/src:ro  # Read-only for production-like behavior
    environment:
      - APP_NAME=cognitive-orch
      - ENVIRONMENT=development
      - DEBUG=true
      - LOG_LEVEL=INFO
      - HOST=0.0.0.0
      - PORT=8001
      - GRPC_PORT=50051
      # LLM Configuration (set these in .env.local or override)
      - DEFAULT_MODEL_NAME=${DEFAULT_MODEL_NAME:-azure/gpt-4o}
      - FALLBACK_MODEL_NAME=${FALLBACK_MODEL_NAME:-anthropic/claude-3-haiku}
      - ENABLE_FALLBACKS=${ENABLE_FALLBACKS:-true}
      - AZURE_API_KEY=${AZURE_API_KEY:-}
      - AZURE_API_BASE=${AZURE_API_BASE:-}
      - AZURE_API_VERSION=${AZURE_API_VERSION:-2024-02-15-preview}
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY:-}
      - GROQ_API_KEY=${GROQ_API_KEY:-}
      # Redis Configuration
      - REDIS_URL=redis://redis:6379/0
      - REDIS_PASSWORD=${REDIS_PASSWORD:-}
      - CONVERSATION_TTL=${CONVERSATION_TTL:-3600}
      # Qdrant Configuration
      - QDRANT_URL=http://qdrant:6333
      - QDRANT_API_KEY=${QDRANT_API_KEY:-}
      # Integration URLs
      - CORE_API_URL=http://api-core:8000
      - CORE_API_TIMEOUT=30
      - INTEGRATION_WORKER_URL=http://integration-worker:8002
      - INTEGRATION_WORKER_TIMEOUT=30
      # Context Window
      - MAX_CONTEXT_WINDOW=8000
      - MAX_HISTORY_MESSAGES=50
      # CORS
      - CORS_ORIGINS=http://localhost:3000,http://localhost:3001
      - PYTHONPATH=/app/src
    command: uvicorn cognitive_orch.main:app --host 0.0.0.0 --port 8001 --reload
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8001/health"]
      interval: 30s
      timeout: 10s
      start_period: 40s
      retries: 3
    networks:
      - lexiqai-network

  # RabbitMQ Message Queue (for document ingestion)
  rabbitmq:
    image: rabbitmq:3-management-alpine
    container_name: lexiqai-rabbitmq-local
    ports:
      - "5672:5672"  # AMQP port
      - "15672:15672"  # Management UI
    environment:
      RABBITMQ_DEFAULT_USER: ${RABBITMQ_USER:-guest}
      RABBITMQ_DEFAULT_PASS: ${RABBITMQ_PASSWORD:-guest}
    volumes:
      - rabbitmq_data:/var/lib/rabbitmq
    healthcheck:
      test: ["CMD", "rabbitmq-diagnostics", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - lexiqai-network

  # Document Ingestion Service (Python FastAPI)
  # Processes knowledge base files for RAG: parsing, chunking, embedding, vector storage
  document-ingestion:
    build:
      context: .
      dockerfile: docker/document-ingestion/Dockerfile
    container_name: lexiqai-document-ingestion-local
    ports:
      - "8003:8003"
    depends_on:
      rabbitmq:
        condition: service_healthy
      qdrant:
        condition: service_started
      api-core:
        condition: service_started
      azurite:
        condition: service_started
    # Add restart policy to handle connection issues
    restart: unless-stopped
    volumes:
      - ./apps/document-ingestion/src:/app/src:ro
      # Mount .env so pydantic-settings can load it (compose env_file is stricter than python-dotenv)
      - ./apps/document-ingestion/.env:/app/.env:ro
    environment:
      - APP_NAME=document-ingestion
      - ENVIRONMENT=development
      - DEBUG=true
      - LOG_LEVEL=INFO
      - HOST=0.0.0.0
      - PORT=8003
      - RELOAD=true
      # RabbitMQ Configuration
      - RABBITMQ_URL=amqp://${RABBITMQ_USER:-guest}:${RABBITMQ_PASSWORD:-guest}@rabbitmq:5672/
      - RABBITMQ_QUEUE_NAME=document-ingestion
      - RABBITMQ_EXCHANGE_NAME=document-ingestion-exchange
      - RABBITMQ_DEAD_LETTER_QUEUE_NAME=document-ingestion-dlq
      - RABBITMQ_ROUTING_KEY=document.ingestion
      - RABBITMQ_PREFETCH_COUNT=10
      - RABBITMQ_QUEUE_DURABLE=true
      # Azure Blob Storage (using Azurite for local dev)
      - STORAGE_ACCOUNT_NAME=devstoreaccount1
      - STORAGE_USE_MANAGED_IDENTITY=false
      - STORAGE_CONNECTION_STRING=DefaultEndpointsProtocol=http;AccountName=devstoreaccount1;AccountKey=Eby8vdM02xNOcqFlqUwJPLlmEtlCDXJ1OUzFT50uSRZ6IFsuFq2UVErCz4I6tq/K1SZFPTOtr/KBHBeksoGMGw==;BlobEndpoint=http://azurite:10000/devstoreaccount1
      # Embeddings config is loaded from ./apps/document-ingestion/.env via env_file
      # Qdrant Configuration
      - QDRANT_URL=http://qdrant:6333
      - QDRANT_API_KEY=${QDRANT_API_KEY:-}
      - QDRANT_COLLECTION_PREFIX=firm_
      - QDRANT_TIMEOUT=30
      # API Core Configuration
      - CORE_API_URL=http://api-core:8000
      - CORE_API_TIMEOUT=30
      # Internal API key for calling API Core internal endpoints
      - CORE_API_API_KEY=${INTERNAL_API_KEY:-}
      # Chunking Configuration
      - CHUNK_SIZE=1000
      - CHUNK_OVERLAP=200
      - CHUNKING_METHOD=sentence
      # Retry Configuration
      - MAX_RETRIES=3
      - RETRY_BACKOFF_FACTOR=2.0
      - RETRY_MAX_DELAY=300
      # Allowed File Types
      - ALLOWED_FILE_TYPES=pdf,docx,txt,md
      - PYTHONPATH=/app/src
    command: uvicorn document_ingestion.main:app --host 0.0.0.0 --port 8003 --reload
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8003/health"]
      interval: 30s
      timeout: 10s
      start_period: 40s
      retries: 3
    networks:
      - lexiqai-network

  # Voice Gateway Service (Go)
  # Handles Twilio WebSocket connections, STT, TTS, and Orchestrator integration
  voice-gateway:
    build:
      context: .
      dockerfile: docker/voice-gateway/Dockerfile
    container_name: lexiqai-voice-gateway-local
    ports:
      - "8080:8080"
    depends_on:
      cognitive-orch:
        condition: service_started
    restart: unless-stopped
    volumes:
      # Mount source for development (optional - comment out for production)
      - ./apps/voice-gateway:/app/src:ro
    environment:
      # Server Configuration
      - PORT=8080
      # Deepgram STT Configuration
      - DEEPGRAM_API_KEY=${DEEPGRAM_API_KEY:-}
      - DEEPGRAM_MODEL=${DEEPGRAM_MODEL:-nova-2}
      - DEEPGRAM_LANGUAGE=${DEEPGRAM_LANGUAGE:-en}
      # Cartesia TTS Configuration
      - CARTESIA_API_KEY=${CARTESIA_API_KEY:-}
      - CARTESIA_VOICE_ID=${CARTESIA_VOICE_ID:-sonic-english}
      - CARTESIA_MODEL_ID=${CARTESIA_MODEL_ID:-sonic}
      # Orchestrator gRPC Configuration
      - ORCHESTRATOR_URL=cognitive-orch:50051
      - ORCHESTRATOR_TLS_ENABLED=false
      - ORCHESTRATOR_TIMEOUT=30
      # Audio Processing Configuration
      - AUDIO_BUFFER_SIZE=${AUDIO_BUFFER_SIZE:-8192}
      - VAD_ENERGY_THRESHOLD=${VAD_ENERGY_THRESHOLD:-500.0}
      - VAD_SILENCE_FRAMES=${VAD_SILENCE_FRAMES:-10}
      # Resilience Configuration
      - CIRCUIT_BREAKER_MAX_FAILURES=${CIRCUIT_BREAKER_MAX_FAILURES:-5}
      - CIRCUIT_BREAKER_RESET_TIMEOUT=${CIRCUIT_BREAKER_RESET_TIMEOUT:-30}
      - RETRY_MAX_ATTEMPTS=${RETRY_MAX_ATTEMPTS:-3}
      - RETRY_INITIAL_BACKOFF=${RETRY_INITIAL_BACKOFF:-100}
      - RECONNECT_MAX_ATTEMPTS=${RECONNECT_MAX_ATTEMPTS:-5}
      - RECONNECT_BACKOFF=${RECONNECT_BACKOFF:-1000}
      # Observability Configuration
      - LOG_LEVEL=${LOG_LEVEL:-info}
      - LOG_PRETTY=${LOG_PRETTY:-false}
      - METRICS_ENABLED=${METRICS_ENABLED:-true}
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      start_period: 10s
      retries: 3
    networks:
      - lexiqai-network

volumes:
  postgres_data:
    driver: local
  redis_data:
    driver: local
  qdrant_data:
    driver: local
  rabbitmq_data:
    driver: local
  azurite_data:
    driver: local

networks:
  lexiqai-network:
    driver: bridge
    name: lexiqai-network

